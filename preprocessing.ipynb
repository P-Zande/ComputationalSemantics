{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecbf2ee",
   "metadata": {},
   "source": [
    "# Token classification\n",
    "This notebook shows our approach to the data preprocessing. The goal is to have exactly one label per token*, including an \"empty\" label.\n",
    "As long as we restrict our data to only one predicate, it should be feasible to determine two what other part of the sentence the role connects to.\n",
    "\n",
    "\\* In this step, token refers to the \"tokenization\" as applied to the PMB, i.e. the tokens in the \"en.tok.off\" files. E.g., \"Alfred Nobel\" is one token here.\n",
    "Our LLM will tokenize our sentence differently, and will create one or more tokens per PMB token. This mapping will be handled later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b43fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ROLES/LABELS: Agent, Location, Topic, Patient, Theme, EMPTY\n",
    "# Tags: 0=EMPTY, 1=Agent, 2=Location, 3=Patient, 4=Theme, 5=Topic\n",
    "\n",
    "# sentence = \"A brown dog and a grey dog are fighting in the snow\"\n",
    "# The goal is to generate:\n",
    "# srl_tags = [1,1,1,1,1,1,1,0,0,2,2,2]b\n",
    "# tokens = ['A', 'brown', 'dog', 'and', 'a', 'grey', 'dog', 'are', 'fighting', 'in', 'the', 'snow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95a0d7a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "# Example with one sentence:\n",
    "# Note: forward slashes for Linux and WSL, backward slashes for Windows\n",
    "# Windows example:\n",
    "# file_path = r'C:\\Users\\bikow\\Documents\\AI\\MSc\\Computational Semantics\\pmb-sample-4.0.0\\data\\en\\gold\\p00\\d0004'\n",
    "# WSL example:\n",
    "# file_path = r'/mnt/c/Users/perry/Documents/uni/Master/CompSem/project/pmb-sample-4.0.0/data/en/gold/p00/d0004/'\n",
    "# file_path = r'/mnt/c/Users/perry/Documents/uni/Master/CompSem/project/pmb-4.0.0/data/en/gold/p01/d2590/' # https://pmb.let.rug.nl/explorer/explore.php?part=01&doc_id=2590&type=der.xml&alignment_language=en\n",
    "file_path = r'/mnt/c/Users/perry/Documents/uni/Master/CompSem/project/pmb-4.0.0/data/en/gold/p03/d0766/' # https://pmb.let.rug.nl/explorer/explore.php?part=03&doc_id=0766&type=der.xml&alignment_language=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05f50e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfred Nobel invented dynamite in 1866 .\n",
      "['Alfred Nobel', 'invented', 'dynamite', 'in', '1866', '.']\n"
     ]
    }
   ],
   "source": [
    "# THIS IS THE GOAL\n",
    "# sentence = \"A brown dog and a grey dog are fighting in the snow\"\n",
    "mapping = {\"Agent\": 1, \"Location\": 2, \"Patient\": 3, \"Theme\": 4, \"Topic\":5, \"Destination\": 6, \"Result\": 7}\n",
    "\n",
    "sentence = \"\"\n",
    "sentence_id = '0'\n",
    "tokens = []\n",
    "\n",
    "# Get the tokens from the tokenized sentence file\n",
    "with open(file_path+\"en.tok.off\") as file:\n",
    "    for line in file:\n",
    "        tokens.append(line.split(maxsplit = 3)[-1].rstrip())\n",
    "\n",
    "sentence = ' '.join(tokens)\n",
    "\n",
    "print(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2342f5",
   "metadata": {},
   "source": [
    "## Our class-based approach\n",
    "We take the en.parse.tags file and recreate the CCG structure using custom classes.\n",
    "This allows us to figure out to what tokens each semantic role label belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9670a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CCGNode:\n",
    "    def __init__(self, category = 'none', rule_type='none', parent=None, level = 0):\n",
    "        self.category = category # eg s\\np or np\n",
    "        self.rule_type = rule_type # fa or ba or conj\n",
    "        self.children = []\n",
    "        self.parent = parent\n",
    "        self.level = level\n",
    "        self.isFirstArgument = True\n",
    "    \n",
    "    def addChild(self, child):\n",
    "        if len(self.children) == 1:\n",
    "            child.isFirstArgument = False\n",
    "        elif len(self.children) == 2:\n",
    "            raise Exception(repr(self), 'already has two children')\n",
    "        self.children.append(child)\n",
    "    \n",
    "    def getSibling(self):\n",
    "        if self.isFirstArgument:\n",
    "            return self.parent.children[1]\n",
    "        else:\n",
    "            return self.parent.children[0]\n",
    "    \n",
    "    def assignTag(self, tag):\n",
    "        self.children[0].assignTag(tag)\n",
    "        if len(self.children) > 1:\n",
    "            self.children[1].assignTag(tag)\n",
    "    \n",
    "    def getTags(self, mapping = None):\n",
    "        if len(self.children) == 1:\n",
    "            return self.children[0].getTags(mapping)\n",
    "        return self.children[0].getTags(mapping) + self.children[1].getTags(mapping)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return ''.join([' ' * self.level, 'CCGNODE', ' ', self.category, ' ', self.rule_type, '\\n', '\\n'.join([repr(child) for child in self.children])])\n",
    "\n",
    "class CCGToken:\n",
    "    def __init__(self, token, category, parent, assignedTag = '', verbnet = [], level = 0):\n",
    "        self.token = token\n",
    "        self.category = category\n",
    "        self.parent = parent\n",
    "        self.assignedTag = assignedTag\n",
    "        self.verbnet = verbnet\n",
    "        self.children = []\n",
    "        self.level = level\n",
    "        self.isFirstArgument = True\n",
    "        \n",
    "    def getSibling(self):\n",
    "        if self.isFirstArgument:\n",
    "            return self.parent.children[1]\n",
    "        else:\n",
    "            return self.parent.children[0]\n",
    "    \n",
    "    def assignTag(self, tag):\n",
    "        self.assignedTag = tag\n",
    "    \n",
    "    def getTags(self, mapping):\n",
    "        if mapping == None:\n",
    "            return [self.assignedTag]\n",
    "        else:\n",
    "            if self.assignedTag == '':\n",
    "                return [0]\n",
    "            return [mapping[self.assignedTag]]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return ''.join([' ' * self.level, 'CCGTOKEN', ' ', self.token, ' ', self.category, ' ', self.assignedTag, ' ',' '.join(self.verbnet)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6fd1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(file_path):\n",
    "    tokens = []\n",
    "    # Get the tokens from the tokenized sentence file\n",
    "    with open(file_path+\"en.tok.off\") as file:\n",
    "        for line in file:\n",
    "            tokens.append(line.split(maxsplit = 3)[-1].rstrip())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'blabla'\n",
    "\n",
    "def getTokensAndLabels(file_path):\n",
    "    tokens = getTokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30a4021f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCGNODE none none\n",
      " CCGNODE s:dcl ba\n",
      "  CCGNODE np lx\n",
      "   CCGTOKEN Alfred Nobel n  \n",
      "  CCGNODE s:dcl\\np ba\n",
      "   CCGNODE s:dcl\\np fa\n",
      "    CCGTOKEN invented (s:dcl\\np)/np  Result Agent\n",
      "    CCGNODE np lx\n",
      "     CCGTOKEN dynamite n  \n",
      "   CCGNODE (s\\np)\\(s\\np) fa\n",
      "    CCGTOKEN in ((s\\np)\\(s\\np))/np  \n",
      "    CCGNODE np rp\n",
      "     CCGNODE np lx\n",
      "      CCGTOKEN 1866 n  \n"
     ]
    }
   ],
   "source": [
    "token_idx = 0\n",
    "topNode = None\n",
    "currentNode = None\n",
    "tokensWithVerbnet = []\n",
    "with open(file_path + \"en.parse.tags\") as file:\n",
    "    skipping = True\n",
    "    previousLevel = 0\n",
    "    for line in file:\n",
    "        if skipping:\n",
    "            if line.startswith('ccg'):\n",
    "                skipping = False\n",
    "                topNode = CCGNode()\n",
    "                currentNode = topNode\n",
    "            continue\n",
    "        if line == '\\n':\n",
    "            continue\n",
    "        trimmedLine = line.lstrip()\n",
    "        nodeType, content = trimmedLine.split('(', 1)\n",
    "        category = content.split(',')[0]\n",
    "        if nodeType == 't':\n",
    "            if category == '.':\n",
    "                continue\n",
    "            vnSplit = content.split(\"verbnet:\")\n",
    "            if len(vnSplit) == 1:\n",
    "                verbnet = []\n",
    "            else:\n",
    "                verbnetLiteral = vnSplit[1].split(']')[0] + ']'\n",
    "                verbnetUnfiltered = eval(verbnetLiteral)\n",
    "                verbnet = [r for r in verbnetUnfiltered if r in mapping.keys()]\n",
    "            \n",
    "            currentNode.addChild(CCGToken(tokens[token_idx], category = category, parent = currentNode, verbnet = verbnet, level = currentNode.level + 1))\n",
    "            if len(verbnet) > 0:\n",
    "                tokensWithVerbnet.append(currentNode.children[-1])\n",
    "            token_idx += 1\n",
    "        else:\n",
    "            level = len(line) - len(trimmedLine)\n",
    "            if level > previousLevel: # This is a child of previous node\n",
    "                currentNode.addChild(CCGNode(category, nodeType, parent=currentNode, level = level))\n",
    "                currentNode = currentNode.children[-1]\n",
    "            elif level == previousLevel: # Sibling of the previous node; same parent\n",
    "                currentNode = currentNode.parent\n",
    "                currentNode.addChild(CCGNode(category, nodeType, parent=currentNode, level = level))\n",
    "                currentNode = currentNode.children[-1]\n",
    "            else: # Go back 1 or more levels\n",
    "                while not currentNode.isFirstArgument:\n",
    "                    currentNode = currentNode.parent\n",
    "                currentNode = currentNode.parent\n",
    "                currentNode.addChild(CCGNode(category, nodeType, parent=currentNode, level = level))\n",
    "                currentNode = currentNode.children[-1]\n",
    "                \n",
    "            previousLevel = level\n",
    "\n",
    "print(topNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57650bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CCG tree with assigned tags (end of CCGTOKENs):\n",
      "CCGNODE none none\n",
      " CCGNODE s:dcl ba\n",
      "  CCGNODE np lx\n",
      "   CCGTOKEN Alfred Nobel n Agent \n",
      "  CCGNODE s:dcl\\np ba\n",
      "   CCGNODE s:dcl\\np fa\n",
      "    CCGTOKEN invented (s:dcl\\np)/np  Result Agent\n",
      "    CCGNODE np lx\n",
      "     CCGTOKEN dynamite n Result \n",
      "   CCGNODE (s\\np)\\(s\\np) fa\n",
      "    CCGTOKEN in ((s\\np)\\(s\\np))/np  \n",
      "    CCGNODE np rp\n",
      "     CCGNODE np lx\n",
      "      CCGTOKEN 1866 n  \n"
     ]
    }
   ],
   "source": [
    "# To do: deal with multiple verbnet labels.\n",
    "\n",
    "def findCorrectLevel(current):\n",
    "    while (not current.category.endswith('np')): # first application with non-nps\n",
    "        current = current.parent\n",
    "    lookingForward = (current.category[-3] == '/')\n",
    "    if lookingForward:\n",
    "        while ((not current.isFirstArgument) or current.parent.rule_type != 'fa'):\n",
    "            current = current.parent\n",
    "    else:\n",
    "        while (current.isFirstArgument or current.parent.rule_type != 'ba'):\n",
    "            current = current.parent\n",
    "    return current\n",
    "\n",
    "for currentTokenWithVerbnet in tokensWithVerbnet:\n",
    "    verbnet = currentTokenWithVerbnet.verbnet\n",
    "    for verbnetItem in verbnet:\n",
    "        currentTokenWithVerbnet = findCorrectLevel(currentTokenWithVerbnet)\n",
    "        sibling = currentTokenWithVerbnet.getSibling()\n",
    "        sibling.assignTag(verbnetItem)\n",
    "        currentTokenWithVerbnet = currentTokenWithVerbnet.parent\n",
    "\n",
    "\n",
    "print('The CCG tree with assigned tags (end of CCGTOKENs):')\n",
    "print(topNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46b707f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alfred Nobel', 'invented', 'dynamite', 'in', '1866', '.']\n",
      "['Agent', '', 'Result', '', '']\n",
      "[1, 0, 7, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokens)\n",
    "print(topNode.getTags())\n",
    "print(topNode.getTags(mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69adfafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
