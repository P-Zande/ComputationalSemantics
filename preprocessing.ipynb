{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecbf2ee",
   "metadata": {},
   "source": [
    "# Token classification\n",
    "This notebook shows our approach to the data preprocessing. The goal is to have exactly one label per token*, including an \"empty\" label.\n",
    "As long as we restrict our data to only one predicate, it should be feasible to determine two what other part of the sentence the role connects to.\n",
    "\n",
    "\\* In this step, token refers to the \"tokenization\" as applied to the PMB, i.e. the tokens in the \"en.tok.off\" files. E.g., \"Alfred Nobel\" is one token here.\n",
    "Our LLM will tokenize our sentence differently, and will create one or more tokens per PMB token. This mapping will be handled later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d48e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from datasets import Dataset\n",
    "mapping = {\"Agent\": 1, \"Location\": 2, \"Patient\": 3, \"Theme\": 4, \"Destination\": 5, \"Result\": 6, \"Stimulus\": 7, \"Experiencer\": 8, \"Co-Theme\": 9, \"Pivot\": 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a0d7a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example with one sentence:\n",
    "# Note: forward slashes for Linux and WSL, backward slashes for Windows\n",
    "# Windows example:\n",
    "# file_path = r'C:\\Users\\yourname\\Documents\\Computational Semantics\\pmb-sample-4.0.0\\data\\en\\gold\\p00\\d0004'\n",
    "# WSL example:\n",
    "file_path = r'/mnt/c/Users/yournamne/Documents/pmb-4.0.0/data/en/gold/p00/d0004/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2342f5",
   "metadata": {},
   "source": [
    "## Our class-based approach\n",
    "We take the en.parse.tags file and recreate the CCG structure using custom classes.\n",
    "This allows us to figure out to what tokens each semantic role label belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9670a3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CCGNode:\n",
    "    def __init__(self, category = 'none', rule_type='none', parent=None, level = 0):\n",
    "        self.category = category # eg s\\np or np\n",
    "        self.rule_type = rule_type # fa or ba or conj\n",
    "        self.children = []\n",
    "        self.parent = parent\n",
    "        self.level = level\n",
    "        self.isFirstArgument = True\n",
    "    \n",
    "    def addChild(self, child):\n",
    "        if len(self.children) == 1:\n",
    "            child.isFirstArgument = False\n",
    "        elif len(self.children) == 2:\n",
    "            raise Exception(repr(self), 'already has two children')\n",
    "        child.level = self.level + 1\n",
    "        self.children.append(child)\n",
    "    \n",
    "    def getSibling(self):\n",
    "        if self.isFirstArgument:\n",
    "            return self.parent.children[1]\n",
    "        else:\n",
    "            return self.parent.children[0]\n",
    "    \n",
    "    def assignTag(self, tag, tagFromTokenIdx):\n",
    "        if tag == '': # Empty tag, we don't need to store this\n",
    "            return\n",
    "        self.children[0].assignTag(tag, tagFromTokenIdx)\n",
    "        if len(self.children) > 1:\n",
    "            self.children[1].assignTag(tag, tagFromTokenIdx)\n",
    "    \n",
    "    def getTags(self, mapping = None):\n",
    "        if len(self.children) == 0:\n",
    "            return []\n",
    "        if len(self.children) == 1:\n",
    "            return self.children[0].getTags(mapping)\n",
    "        return self.children[0].getTags(mapping) + self.children[1].getTags(mapping)\n",
    "    \n",
    "    def getCategories(self, onlyTokens = False):\n",
    "        if onlyTokens:\n",
    "            x = []\n",
    "        else:\n",
    "            x = [self.category]\n",
    "        if len(self.children) == 0:\n",
    "            return x\n",
    "        if len(self.children) == 1:\n",
    "            return x + self.children[0].getCategories(onlyTokens)\n",
    "        return x + self.children[0].getCategories(onlyTokens) + self.children[1].getCategories(onlyTokens)\n",
    "    \n",
    "    \n",
    "    def getTagsFromTokenIdx(self):\n",
    "        if len(self.children) == 0:\n",
    "            return []\n",
    "        if len(self.children) == 1:\n",
    "            return self.children[0].getTagsFromTokenIdx()\n",
    "        return self.children[0].getTagsFromTokenIdx() + self.children[1].getTagsFromTokenIdx()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return ''.join([' ' * self.level, 'CCGNODE', ' ', self.category, ' ', self.rule_type, '\\n', '\\n'.join([repr(child) for child in self.children])])\n",
    "\n",
    "class CCGToken:\n",
    "    def __init__(self, token, category, parent, assignedTag = '', verbnet = [], tokenIdx = 0):\n",
    "        self.token = token\n",
    "        self.category = category\n",
    "        self.parent = parent\n",
    "        self.assignedTag = assignedTag\n",
    "        self.verbnet = verbnet\n",
    "        self.children = []\n",
    "        self.level = None\n",
    "        self.isFirstArgument = True\n",
    "        self.tokenIdx = tokenIdx\n",
    "        self.tagFromTokenIdx = None\n",
    "        \n",
    "    def getSibling(self):\n",
    "        if self.isFirstArgument:\n",
    "            return self.parent.children[1]\n",
    "        else:\n",
    "            return self.parent.children[0]\n",
    "    \n",
    "    def assignTag(self, tag, tagFromTokenIdx):\n",
    "        self.assignedTag = tag\n",
    "        self.tagFromTokenIdx = tagFromTokenIdx\n",
    "    \n",
    "    def getTags(self, mapping):\n",
    "        if mapping == None:\n",
    "            return [self.assignedTag]\n",
    "        else:\n",
    "            if self.assignedTag == '':\n",
    "                return [0]\n",
    "            return [mapping[self.assignedTag]]\n",
    "    \n",
    "    def getCategories(self, _):\n",
    "        return [self.category]\n",
    "    \n",
    "    def getTagsFromTokenIdx(self):\n",
    "        return [self.tagFromTokenIdx]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return ''.join([' ' * self.level, 'CCGTOKEN', ' ', self.token, ' ', self.category, ' ', self.assignedTag, ' ',' '.join(self.verbnet)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6bbb82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getTokens(file_path):\n",
    "    tokens = []\n",
    "    # Get the tokens from the tokenized sentence file\n",
    "    with open(os.path.join(file_path, \"en.tok.off\")) as file:\n",
    "        for line in file:\n",
    "            token = line.split(maxsplit = 3)[-1].rstrip()\n",
    "            tokens.append(token)\n",
    "            if token in ['.', '?', '!', ';', '...', '!!']:\n",
    "                break\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a4021f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getTree(file_path, tokens):\n",
    "    tokenIdx = 0\n",
    "    topNode = None\n",
    "    currentNode = None\n",
    "    tokensWithVerbnet = []\n",
    "    with open(os.path.join(file_path, \"en.parse.tags\")) as file:\n",
    "        skipping = True\n",
    "        for line in file:\n",
    "            if skipping:\n",
    "                if line.startswith('ccg'):\n",
    "                    skipping = False\n",
    "                    topNode = CCGNode()\n",
    "                    currentNode = topNode\n",
    "                continue\n",
    "            if line == '\\n':\n",
    "                continue\n",
    "            if line.startswith('ccg'): # Second sentence starts, we ignore this\n",
    "                return topNode, tokensWithVerbnet\n",
    "            trimmedLine = line.lstrip()\n",
    "            nodeType, content = trimmedLine.split('(', 1)\n",
    "            category = content.split(',')[0]\n",
    "            level = len(line) - len(trimmedLine)\n",
    "            while level <= currentNode.level:\n",
    "                currentNode = currentNode.parent\n",
    "            if nodeType == 't':\n",
    "                if category in ['.']:\n",
    "                    break\n",
    "                if tokens[tokenIdx] in ['.', '!', '?', ';']:\n",
    "                    break\n",
    "                \n",
    "                vnSplit = content.split(\"verbnet:\")\n",
    "                if len(vnSplit) == 1:\n",
    "                    verbnet = []\n",
    "                else:\n",
    "                    # It needs to combine to an np. Verbnet tags looking for a n for example,\n",
    "                    # often describe adjectives and are not relevant for the main predicate\n",
    "                    searchingFor = re.split(r'[\\\\\\/]', category, 1)\n",
    "                    if len(searchingFor) > 1 and (\"np\" in searchingFor[1]):\n",
    "                        verbnetLiteral = vnSplit[1].split(']')[0] + ']'\n",
    "                        verbnetUnfiltered = eval(verbnetLiteral)\n",
    "                        for role in verbnetUnfiltered:\n",
    "                            verbnetCounter[role] = verbnetCounter.get(role, 0) + 1\n",
    "                        # If first element gets filtered out but not the second, replace with dummy value\n",
    "                        verbnet = [r if r in mapping.keys() else '' for r in verbnetUnfiltered]\n",
    "                        # Remove trailing dummy values\n",
    "                        while (verbnet) and (verbnet[-1] == ''):\n",
    "                            verbnet.pop()\n",
    "                    else:\n",
    "                        verbnet = []\n",
    "                currentNode.addChild(CCGToken(tokens[tokenIdx], category = category, parent = currentNode, verbnet = verbnet, tokenIdx = tokenIdx))\n",
    "                if len(verbnet) > 0:\n",
    "                    tokensWithVerbnet.append(currentNode.children[-1])\n",
    "                tokenIdx += 1\n",
    "            else:\n",
    "                currentNode.addChild(CCGNode(category, nodeType, parent=currentNode, level = level))\n",
    "                currentNode = currentNode.children[-1]\n",
    "\n",
    "\n",
    "    return topNode, tokensWithVerbnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ae4d97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findCorrectLevel(current):\n",
    "    while (not current.category.endswith('np')): # first application with non-nps\n",
    "        current = current.parent\n",
    "    lookingForward = (current.category[-3] == '/')\n",
    "    if lookingForward:\n",
    "        while ((not current.isFirstArgument) or current.parent.rule_type != 'fa'):\n",
    "            current = current.parent\n",
    "    else:\n",
    "        while (current.isFirstArgument or current.parent.rule_type != 'ba'):\n",
    "            current = current.parent\n",
    "    return current\n",
    "\n",
    "def assignTags(tokensWithVerbnet):\n",
    "    for currentTokenWithVerbnet in tokensWithVerbnet:\n",
    "        verbnet = currentTokenWithVerbnet.verbnet\n",
    "        currentTokenIdx = round(currentTokenWithVerbnet.tokenIdx + 0.0, 1)\n",
    "        for verbnetItem in verbnet:\n",
    "            currentTokenWithVerbnet = findCorrectLevel(currentTokenWithVerbnet)\n",
    "            sibling = currentTokenWithVerbnet.getSibling()\n",
    "            sibling.assignTag(verbnetItem, currentTokenIdx)\n",
    "            currentTokenWithVerbnet = currentTokenWithVerbnet.parent\n",
    "            currentTokenIdx = round(currentTokenIdx + 0.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3882f090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def skipSentence(topNode, tokens):\n",
    "    allCategories = topNode.getCategories()\n",
    "    \n",
    "    # Skip W-questions\n",
    "    if 's:wq' in allCategories:\n",
    "        return True\n",
    "    \n",
    "    # Skip sentences with \"there\"\n",
    "    if 'np:thr' in allCategories:\n",
    "        return True\n",
    "    \n",
    "    # Skip sentenses with \"'s\" as \"us\"\n",
    "    for idx, token in enumerate(tokens):\n",
    "        if token.lower() == \"let\":\n",
    "            if tokens[idx + 1] in [\"'s\", \"us\"]:\n",
    "                return True\n",
    "    \n",
    "    # Skip sentences that miss a part (like \"Think about it\")\n",
    "    if (\"/\" in topNode.children[0].category) or (\"\\\\\" in topNode.children[0].category):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"Theme\": 1, \"Agent\": 2, \"Patient\": 3, \"Experiencer\": 4, \"Co-Theme\": 5, \"Stimulus\": 6, \"Location\": 7, \"Destination\": 8}\n",
    "\n",
    "def getTokensAndLabels(file_path):\n",
    "    tokens = getTokens(file_path)\n",
    "    topNode, tokensWithVerbnet = getTree(file_path, tokens)\n",
    "    if skipSentence(topNode, tokens):\n",
    "        return None, None, None\n",
    "    try:\n",
    "        assignTags(tokensWithVerbnet)\n",
    "    except AttributeError:\n",
    "        skippedDirs.append(file_path)\n",
    "        return None, None, None\n",
    "    assignTags(tokensWithVerbnet)\n",
    "    labels = topNode.getTags(mapping)\n",
    "    origin = topNode.getTagsFromTokenIdx()\n",
    "    if tokens[-1] not in ['.', '!', '?', ';', '...', '!!']:\n",
    "        tokens.append('.')\n",
    "    if len(tokens) > len(labels):\n",
    "        labels.append(0)\n",
    "        origin.append(None)\n",
    "    if len(tokens) != len(labels):\n",
    "        raise Exception(file_path, 'Length of token and labels does not match up!')\n",
    "    return tokens, labels, origin\n",
    "    \n",
    "verbnetCounter = {}\n",
    "skippedDirs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e04fcec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'brown', 'dog', 'and', 'a', 'grey', 'dog', 'are', 'fighting', 'in', 'the', 'snow', '.']\n",
      "[2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 7, 7, 0]\n",
      "[8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, None, None, None, 9.0, 9.0, None]\n"
     ]
    }
   ],
   "source": [
    "file_path = r'/mnt/c/Users/perry/Documents/uni/Master/CompSem/project/pmb-4.0.0/data/en/gold/p00/d0004/' # As an example\n",
    "tokens, labels, origin = getTokensAndLabels(file_path)\n",
    "print(tokens)\n",
    "print(labels)\n",
    "print(origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ea282a",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69adfafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_path = r'/mnt/c/Users/perry/Documents/uni/Master/CompSem/project/pmb-4.0.0/data/en/gold/' \n",
    "\n",
    "def createDataset(parent_dir):\n",
    "    i = 0\n",
    "    dataset = {'tokens': [], 'labels': [], 'origin': []}\n",
    "    for subdir, dirs, files in os.walk(parent_dir):\n",
    "        if not os.path.exists(os.path.join(subdir, 'en.parse.tags')):\n",
    "            continue\n",
    "        i += 1\n",
    "        if (i % 100 == 0):\n",
    "            print(i)\n",
    "        tokens, labels, origin = getTokensAndLabels(subdir)\n",
    "        if tokens == None:\n",
    "            continue\n",
    "        dataset['tokens'].append(tokens)\n",
    "        dataset['labels'].append(labels)\n",
    "        dataset['origin'].append(origin)\n",
    "    return dataset\n",
    "        \n",
    "\n",
    "dataset = createDataset(folder_path)\n",
    "\n",
    "ds = Dataset.from_dict(dataset)\n",
    "ds.save_to_disk(\"dataset.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "79884841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9243\n",
      "[('Theme', 5872), ('Agent', 4634), ('Patient', 1456), ('Attribute', 1374), ('Experiencer', 1345), ('Co-Theme', 1188), ('Stimulus', 1030), ('Location', 1025), ('Destination', 569), ('Equal', 472), ('Source', 412), ('Pivot', 367), ('Time', 359), ('Value', 349), ('Result', 309), ('Recipient', 306), ('Name', 284), ('PartOf', 241), ('Co-Agent', 222), ('Topic', 206), ('Beneficiary', 198), ('Instrument', 147), ('User', 145), ('Causer', 143), ('Of', 118), ('Manner', 117), ('Duration', 107), ('Quantity', 104), ('Colour', 91), ('Product', 84), ('SubOf', 81), ('Creator', 74), ('Goal', 71), ('Asset', 62), ('Path', 59), ('InstanceOf', 58), ('Context', 50), ('Bearer', 46), ('Material', 36), ('Frequency', 30), ('Extent', 28), ('AttributeOf', 22), ('Co-Patient', 22), ('Start', 20), ('Finish', 19), ('Owner', 18), ('Unit', 17), ('Part', 14), ('Content', 8), ('ContentOf', 4), ('Sub', 4), ('Similar', 2), ('Instance', 2), ('MadeOf', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Total number of roles in the dataset:\n",
    "print(len(dataset['tokens']))\n",
    "# Frequency of roles\n",
    "print(sorted(verbnetCounter.items(), key=lambda x:x[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ebcd79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To see the sentences that have been skipped:\n",
    "print(skippedDirs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
